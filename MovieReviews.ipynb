{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27b617f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSentiment\\nAnalysis\\n\\nStudent A applied Textblob to classify positive and negative reviews\\nStudent B used Pandas to analyse the result of the sentiment analysis\\n\\nCollocation\\nExtraction\\n\\nStudent A implemented the frequency based collocation extraction\\nStudent B implemented the frequency based collocation extraction with pos filtering\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sentiment\n",
    "Analysis\n",
    "\n",
    "Student A applied Textblob to classify positive and negative reviews\n",
    "Student B used Pandas to analyse the result of the sentiment analysis\n",
    "\n",
    "Collocation\n",
    "Extraction\n",
    "\n",
    "Student A implemented the frequency based collocation extraction\n",
    "Student B implemented the frequency based collocation extraction with pos filtering\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88a2c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student A applied Textblob to classify positive and negative reviews\n",
    "# Chris     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c370ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import plotly.express as px\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e98a20c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ReviewID     MovieID                                        MovieReview\n",
      "0         1  076780192X  it always amazes me how people can rate the DV...\n",
      "1         2  0767821599  This movie is okay, but, its not worth what th...\n",
      "2         3  0782008380  If you love the Highlander 1 movie and the ser...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Movie_reviews.csv\", sep=\"\\t\", header = None)\n",
    "df.columns = [\"ReviewID\", \"MovieID\", \"MovieReview\"]\n",
    "#df = df[0:20] ##TEST VALUES\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "744f624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ReviewID     MovieID                                        MovieReview\n",
      "0         1  076780192X  it always amazes me how people can rate the dv...\n",
      "1         2  0767821599  this movie is okay but its not worth what they...\n",
      "2         3  0782008380  if you love the highlander  movie and the seri...\n"
     ]
    }
   ],
   "source": [
    "#df[\"MovieReview\"] = df[\"MovieReview\"].replace(    \"[?,.():;'!Â£@#<>/\\\"&]\", '', regex=True)  # removing punctuation\n",
    "df[\"MovieReview\"] = df[\"MovieReview\"].str.lower()  # making lower case\n",
    "import string\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = str(text)\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "df[\"MovieReview\"] = df['MovieReview'].apply(remove_punctuations) # removes any punctuation\n",
    "df['MovieReview'] = df['MovieReview'].replace('\\d+','', regex = True) # removes any numbers\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ceda0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "for i in df.index:\n",
    "    df.at[i, 'MovieReview'] = spell(df[\"MovieReview\"][i])\n",
    "    \n",
    "#print(df[\"MovieReview\"][516])\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8617948",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For loop to check all reviews uploaded corrrectly\n",
    "\"\"\"\n",
    "for x in df[\"Review\"]: # For row in the review column\n",
    "    print(x) # Prints each review\n",
    "    print(type(x)) # To check they are strings\n",
    "    print(\"\\n\") # For a space for each review\n",
    "\"\"\"\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5755f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check individ sentance score\n",
    "\"\"\"\n",
    "for z in df[\"Review\"]: # For row in review\n",
    "    zx = str(x)\n",
    "    blob = TextBlob(z) # Input review\n",
    "    for sentance in blob.sentences: # Checks each sentance in review\n",
    "        print (sentance, '\\t', sentance.sentiment.polarity) #Prints individ sentance score\n",
    "    print(\"\\n\") # Space for each review\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates score of the each review\n",
    "\n",
    "listOfScore = []\n",
    "for x in df[\"MovieReview\"]: # For each row in the dataset\n",
    "    w = str(x)\n",
    "    score = 0\n",
    "    blob = TextBlob(w) # Input review\n",
    "    for sentence in blob.sentences: # Checks each sentence in the dataset\n",
    "        score += sentence.sentiment.polarity\n",
    "    listOfScore.append(score)\n",
    "print(listOfScore[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89eed37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(listOfScore) # Check all scores are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(score):\n",
    "    if score < 0:\n",
    "        listForDF.append(\"Negative\")\n",
    "    elif score == 0:\n",
    "        listForDF.append(\"Neutral\")\n",
    "    else:\n",
    "        listForDF.append(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "listForDF = [] # Empty list to add sentiment\n",
    "for value in listOfScore:\n",
    "    getSentiment(value) # Function call\n",
    "len(listForDF) # Check size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc403439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns with sentiment score and meaning of score e.g pos or neg\n",
    "df['Sentiment Num'] = listOfScore\n",
    "df['Sentiment'] = listForDF\n",
    "df.head(5) # Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677eecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student B used Pandas to analyse the result of the sentiment analysis\n",
    "# Charlotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, y = \"Sentiment Num\", x = \"Sentiment\", color = \"Sentiment\")\n",
    "fig.update_traces(marker_size = 10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4788ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df, x = \"Sentiment\", color = \"Sentiment\", text_auto = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df, x=\"Sentiment\", y = \"Sentiment Num\", color = \"Sentiment\", points = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(df, x=\"Sentiment\", y=\"Sentiment Num\", color=\"Sentiment\").update_traces(jitter=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(df, y = \"Sentiment Num\", color = \"Sentiment\", stripmode = \"overlay\").update_traces(jitter=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af955e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "for i in df.index:\n",
    "    a = df['MovieReview'][i]\n",
    "    text_tokens = word_tokenize(a)\n",
    "    b = [\n",
    "        word for word in text_tokens if not word in stopwords.words('english')]\n",
    "    c = \"\"\n",
    "    for j in b:\n",
    "        c = c + j + \" \"\n",
    "    df.at[i, 'MovieReview'] = c\n",
    "\n",
    "#print(df[\"MovieReview\"][516])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocation(data):\n",
    "    word = []\n",
    "    for x in data[\"MovieReview\"]: # every review\n",
    "        token = nltk.word_tokenize(x) # adds all words into a list\n",
    "        output = list(nltk.bigrams(token)) # generates bigrams from the list\n",
    "        for i in output: # adds each bigram to the list\n",
    "            word.append(i)\n",
    "\n",
    "    bigrams_w_freq = {}\n",
    "    for first, second in word: # first and second word in the bigram\n",
    "        if (first, second) in bigrams_w_freq: # if they are already in the dictionary\n",
    "            bigrams_w_freq[(first, second)] += 1 \n",
    "        #elif (second, first) in bigrams_w_freq: # if they are already in the dictionary in other combination\n",
    "         #   bigrams_w_freq[(first, second)] += 1\n",
    "        else: # if they are not already in the dictionary\n",
    "            bigrams_w_freq[(first, second)] = 1\n",
    "\n",
    "    freq_sorted = dict(sorted(bigrams_w_freq.items(), key = lambda x: x[1], reverse=True)) # sorts them numerically\n",
    "    counts = dict(list(freq_sorted.items())[0:40]) # first 40 values\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df[df[\"Sentiment\"] == \"Positive\"]\n",
    "collocation(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84046072",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = df[df[\"Sentiment\"] == \"Negative\"]\n",
    "collocation(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neutral = df[df[\"Sentiment\"] == \"Neutral\"]\n",
    "#print(neutral.head(2))\n",
    "#collocation(neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import bigrams\n",
    "def POS(data):\n",
    "    word = []\n",
    "    for i in data['MovieReview']:\n",
    "        words = word_tokenize(i) # adds all words to a list\n",
    "        words_with_POS_tags = pos_tag(words) # assigns POS tags to all\n",
    "        bigrams_with_POS_tags = list(bigrams(words_with_POS_tags)) # generates bigrams from the list\n",
    "        for i in bigrams_with_POS_tags:  # adds each bigram to the list\n",
    "            word.append(i)\n",
    "        \n",
    "    bigrams_with_freq = {}\n",
    "    for first, second in word:\n",
    "        first_word, first_POS = first[0], first[1]\n",
    "        second_word, second_POS = second[0], second[1]\n",
    "        if (first_word, second_word) in bigrams_with_freq: # already in the dictionary\n",
    "            bigrams_with_freq[(first_word, second_word)] += 1\n",
    "        elif (second_word, first_word) in bigrams_with_freq: # if they are already in the dictionary in other combination\n",
    "            bigrams_with_freq[(second_word, first_word)] += 1\n",
    "        else: # not in the dictionary\n",
    "            bigrams_with_freq[(first_word, second_word)] = 1\n",
    "    \n",
    "    freq_sorted = dict(sorted(bigrams_with_freq.items(), key=lambda x: x[1], reverse=True))  # sorts them numerically\n",
    "    counts = dict(list(freq_sorted.items())[0:40])  # first 40 values\n",
    "    print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e35ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df[df[\"Sentiment\"] == \"Positive\"]\n",
    "POS(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = df[df[\"Sentiment\"] == \"Negative\"]\n",
    "POS(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc043f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neutral = df[df[\"Sentiment\"] == \"Neutral\"]\n",
    "#POS(neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8afbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST!!!\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import bigrams\n",
    "\n",
    "\n",
    "def POS(data):\n",
    "    word = []\n",
    "    for i in data['MovieReview']:\n",
    "        words = word_tokenize(i)  # adds all words to a list\n",
    "        words_with_POS_tags = pos_tag(words)  # assigns POS tags to all\n",
    "        # generates bigrams from the list\n",
    "        bigrams_with_POS_tags = list(bigrams(words_with_POS_tags))\n",
    "        for i in bigrams_with_POS_tags:  # adds each bigram to the list\n",
    "            word.append(i)\n",
    "\n",
    "    bigrams_with_freq = {}\n",
    "    for first, second in word:\n",
    "        first_word, first_POS = first[0], first[1]\n",
    "        second_word, second_POS = second[0], second[1]\n",
    "        if first_POS in (\"IN\", \"TO\", \"DT\", \"CC\", \"PRP\", \"PRP%\"): # removing certain POS tags\n",
    "            continue\n",
    "        elif second_POS in (\"IN\", \"TO\", \"DT\", \"CC\", \"PRP\", \"PRP%\"):\n",
    "            continue\n",
    "        elif (first_word, second_word) in bigrams_with_freq:  # already in the dictionary\n",
    "            bigrams_with_freq[(first_word, second_word)] += 1\n",
    "            # if they are already in the dictionary in other combination\n",
    "        elif (second_word, first_word) in bigrams_with_freq:\n",
    "            bigrams_with_freq[(second_word, first_word)] += 1\n",
    "        else:  # not in the dictionary\n",
    "            bigrams_with_freq[(first_word, second_word)] = 1\n",
    "\n",
    "\n",
    "    freq_sorted = dict(sorted(bigrams_with_freq.items(), key=lambda x: x[1], reverse=True))  # sorts them numerically\n",
    "    counts = dict(list(freq_sorted.items())[0:40])  # first 40 values\n",
    "    print(counts)\n",
    "\n",
    "negative = df[df[\"Sentiment\"] == \"Negative\"]\n",
    "POS(negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7122d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
